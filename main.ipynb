{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97b4ac5f",
      "metadata": {
        "id": "97b4ac5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86f71dda-47b1-45ed-b720-38fc964d69cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.3)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 5.50.0 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "Hit:1 https://cli.github.com/packages stable InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 57 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install -U pip\n",
        "%pip install -Uq \"unstructured[all-docs]\" Pillow lxml\n",
        "%pip install -Uq chromadb tiktoken\n",
        "%pip install -Uq langchain langchain-community langchain-openai\n",
        "%pip install -Uq python_dotenv\n",
        "!apt-get update\n",
        "!apt-get install -y poppler-utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Need for Colab\n",
        "#!pip install -q --upgrade \"Pillow<11\""
      ],
      "metadata": {
        "id": "tKRg1bsUiVFh"
      },
      "id": "tKRg1bsUiVFh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af1c2193",
      "metadata": {
        "id": "af1c2193",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fc7922a-e742-4e5f-8beb-e77915e8df44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#For Local Run\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XmtivmNcutCx",
      "metadata": {
        "id": "XmtivmNcutCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c8e1af8-fb79-4e52-8d06-315a234b13fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#For Colab Run\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b1b7e32",
      "metadata": {
        "id": "1b1b7e32"
      },
      "outputs": [],
      "source": [
        "from unstructured.partition.pdf import partition_pdf\n",
        "import os\n",
        "\n",
        "path = os.path.join(os.getcwd(), \"drive/MyDrive/Colab Notebooks/RAG/RRMenu.pdf\")\n",
        "\n",
        "chunks = partition_pdf(\n",
        "    filename=path,                                                              # only required parameter\n",
        "    infer_table_structure=False,                                                 # extract tables\n",
        "    strategy=\"auto\",                                                            # mandatory to infer tables, \"high-res\" if you extract tables\n",
        "    languages=[\"eng\"],\n",
        "    skip_infer_table_types=True,\n",
        "    # extract_image_block_types=[\"Image\"],                                      # add 'Table' to list to extrac image of table\n",
        "    # extract_image_block_output_dir= \"path\",                                   # if none, images and tables will be saved in base64\n",
        "\n",
        "    # chunking groups related information | Useful for RAG\n",
        "    chunking_strategy=\"by_title\",                                               # or \"basic\" | Menu has clear titles\n",
        "    max_characters=10000,                                                       # max size of chunk\n",
        "    combine_text_under_n_chars=2000,                                            # comebine different elements when they are under 2000 characters\n",
        "    new_after_n_chars=6000                                                      # start new part after 6000 characters\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "413762b4",
      "metadata": {
        "id": "413762b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "985da143-a2e6-4add-ed7f-76f93a4c3122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ],
      "source": [
        "print(len(chunks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d54e0e3",
      "metadata": {
        "id": "0d54e0e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9399522-0458-4a24-811a-b61d49a72981"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'type': 'CompositeElement',\n",
              " 'element_id': '43c2099fd4e91cc48e55834faccbbcbd',\n",
              " 'text': 'GOURMET FIRE-GRILLED BURGERS\\n\\nALL BURGERS INCLUDE A BOTTOMLESS SIDE\\n\\nSteak Fries ‚Ä¢ Yukon Chips ‚Ä¢ Steamed Broccoli ‚Ä¢ Side Salad Sweet Potato Fries (1.79) ‚Ä¢ Garlic Fries (1.79)\\n\\nOUR SIGNATURES Burgers you won‚Äôt find anywhere else. 100% Fresh, Never Frozen Beef.\\n\\nTHE SOUTHERN CHARM BURGER¬Æ Brown sugar glaze, candied bacon, Whiskey River¬Æ BBQ Sauce, Cheddar, caramelized onions, lettuce and mayo on a toasted brioche bun. 14.99 cal 1190\\n\\nBLACK & BLEU\\n\\nSaut√©ed and blackened portobello mushrooms, caramelized onions, creamy cheese sauce, Bleu cheese crumbles, lettuce and roasted garlic aioli on a toasted brioche bun. 15.39 cal 980\\n\\nWHISKEY RIVER¬Æ BBQ\\n\\nDIP IT. DUNK IT. DOUSE YOUR BURGER.\\n\\nWhiskey River¬Æ BBQ Sauce, crispy onion straws, Cheddar, lettuce, tomatoes and mayo on a toasted sesame bun. 13.79 cal 1140 THE MADLOVE BURGER A Cheddar-and-Parmesan crisp, Provolone, Swiss, jalape√±o relish, candied bacon, avocado, citrus- marinated tomatoes and red onions with lettuce on a toasted brioche bun. 15.39 cal 1060 BURNIN‚Äô LOVE BURGER¬Æ Fried jalape√±o coins, house-made salsa, Pepper-Jack, lettuce, tomatoes and chipotle aioli on a toasted sesame bun. 14.49 cal 920 Also available with grilled chicken. cal 740\\n\\nSMOKE & PEPPER‚Ñ¢\\n\\nBlack-peppered bacon, Cheddar, lettuce, dill pickle planks and Smoke & Pepper‚Ñ¢ ketchup on a toasted brioche bun. 14.99 cal 800\\n\\nSCORPION GOURMET BURGER\\n\\nSCORPION GOURMET BURGER Scorpion Pepper Sauce, Pepper-Jack, fried jalape√±o coins, lettuce, tomatoes, pickles, red onions and jalape√±os roasted in Scorpion sauce and roasted garlic aioli on a toasted sesame bun. 15.39 cal 960\\n\\nROYAL RED ROBIN BURGER¬Æ Hardwood-smoked bacon, egg‚ô¶, American cheese, lettuce, tomatoes and mayo on a toasted sesame bun. 14.49 cal 1100\\n\\nBANZAI\\n\\nTeriyaki-glazed patty, grilled pineapple, Cheddar, lettuce, tomatoes and mayo on a toasted sesame bun. 13.69 cal 950\\n\\nLimited Time PRETZEL BACON BEER-CHEESE BURGER\\n\\nFire-grilled beef burger topped with Cheddar cheese, hardwood-smoked bacon and mayo on a toasted pretzel bun. Served with New Belgium¬Æ Fat Tire¬Æ beer cheese fondue for dipping and Bottomless Steak Fries¬Æ. 15.29 cal 1730 Dip It. Dunk It. Douse It.',\n",
              " 'metadata': {'file_directory': '/content/drive/MyDrive/Colab Notebooks/RAG',\n",
              "  'filename': 'RRMenu.pdf',\n",
              "  'languages': ['eng'],\n",
              "  'last_modified': '2025-11-26T20:39:29',\n",
              "  'page_number': 1,\n",
              "  'orig_elements': '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',\n",
              "  'filetype': 'application/pdf'}}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "chunks[0].to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be4fb0df",
      "metadata": {
        "id": "be4fb0df"
      },
      "outputs": [],
      "source": [
        "texts = []\n",
        "\n",
        "for chunk in chunks:\n",
        "    if \"CompositeElement\" in str(type((chunk))):\n",
        "        texts.append(chunk)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "\n",
        "# Chunks --> Langchain Documents\n",
        "documents = []\n",
        "for chunk in texts:\n",
        "  documents.append(Document(page_content = chunk.text,\n",
        "                            metadata=chunk.metadata.to_dict()                   # Document() expects metadata as a dict, not unstrucuted metadata\n",
        "                            )\n",
        "  )\n",
        "\n"
      ],
      "metadata": {
        "id": "1mZY8qB6Ao-T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a7dc183-2b67-4a06-95b7-a09085138427"
      },
      "id": "1mZY8qB6Ao-T",
      "execution_count": null,
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
        "from langchain_community.vectorstores import Chroma\n",
        "import shutil, os\n",
        "\n",
        "filtered_docs = filter_complex_metadata(documents)                              # langchain doesnt like unstructureds metadata structure\n",
        "\n",
        "# create embeddings for vector storage\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")               # huggingface is free\n",
        "\n",
        "# remove chroma_db so you dont re-store data\n",
        "shutil.rmtree(\"./chroma_db\", ignore_errors=True)\n",
        "os.makedirs(\"./chroma_db\", exist_ok=True)\n",
        "\n",
        "# Create vectorstore\n",
        "vectorstore = Chroma.from_documents(filtered_docs,\n",
        "                                    embeddings,\n",
        "                                    persist_directory=\"./chroma_db\"\n",
        "                                    )"
      ],
      "metadata": {
        "id": "to4GxaNFDNYF"
      },
      "id": "to4GxaNFDNYF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get a tuple of the top k chunks and their scores based on their similarity score (i.e. cosine sim)\n",
        "results = vectorstore.similarity_search_with_relevance_scores(\"Can i make a custom pizza?\", k=3)\n",
        "\n",
        "# print top k docs and their score\n",
        "for doc, score in results:\n",
        "    print(f\"Score:  {score} \\nText: {doc.page_content} \\n {'-'*100}\")"
      ],
      "metadata": {
        "id": "VCsT_mTtJA9g"
      },
      "id": "VCsT_mTtJA9g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers, torch, os\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(token=os.getenv(\"HF_TOKEN\"))\n",
        "\n",
        "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "\n",
        "pipe = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    model_kwargs={\"torch_dtype\": torch.bfloat16},                               # half the size of weight\n",
        "    device_map=\"auto\"                                                           # tries gpu, then cpu\n",
        ")\n"
      ],
      "metadata": {
        "id": "iExRWcD8eoX0"
      },
      "id": "iExRWcD8eoX0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Which burgers are vegetarian?\"                                         # user input\n",
        "context = \"\\n\\n\".join(doc.page_content for doc, _ in results[:3])\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"Answer only from the menu below. Be brief.\"},\n",
        "    {\"role\": \"user\", \"content\": f\"Menu:\\n{context}\\n\\n{query}\"}\n",
        "]\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=150,                                                         # number of tokens to generate\n",
        "    temperature=0.6,                                                            # more likely to select most probable word (logit / 0.7)\n",
        "    do_sample=True,                                                             # need to set this to true for temperature to have any effect\n",
        "    top_p=0.9,                                                                  # model choses from top tokens that make up 90% of the probability mass (ignores super low prob tokens from being selected)\n",
        "    pad_token_id=pipe.tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "# last element is the llm reply\n",
        "answer = outputs[0][\"generated_text\"][-1][\"content\"]\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "ETfK9XRDStHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "495da8be-8d3d-4b49-cd10-5b727b73fba0"
      },
      "id": "ETfK9XRDStHO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Impossible‚Ñ¢ burger, Veggie burger, and The WORKS burger (with mushrooms and no meat) are vegetarian options.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def chat_interface(message, history):\n",
        "    response = answer(message)\n",
        "    history.append((message, response))\n",
        "    return history, \"\"   # clear textbox\n",
        "\n",
        "css = \"\"\"\n",
        "\n",
        "@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&display=swap');\n",
        "\n",
        "* {\n",
        "  font-family: \"Inter\", sans-serif !important;\n",
        "}\n",
        "\n",
        "/* Root background and general text color */\n",
        "#root {\n",
        "  background-color: #2e3532;\n",
        "  color: #e0e2db;\n",
        "  padding: 18px;\n",
        "  min-height: 100vh;\n",
        "}\n",
        "\n",
        "/* Chat container (box that holds messages) */\n",
        "#chatbot {\n",
        "  background-color: #e0e2db;\n",
        "  color: #2e3532;\n",
        "  border-radius: 12px;\n",
        "  padding: 20px;\n",
        "  max-height: 480px;\n",
        "  overflow-y: auto;\n",
        "  margin: 0 auto;\n",
        "  width: 85%;\n",
        "  box-shadow: 0px 4px 18px rgba(0,0,0,0.15);\n",
        "}\n",
        "\n",
        "/* User message bubble (attempt to match Gradio's generated classes) */\n",
        "#chatbot .message.user,\n",
        "#chatbot .chatbot-message.user {\n",
        "  background: #73BA9B;\n",
        "  color: white;\n",
        "  border-radius: 12px 12px 0 12px; /* rounded bottom-left square */\n",
        "  padding: 10px 14px;\n",
        "  margin: 6px 0;\n",
        "  max-width: 80%;\n",
        "  box-shadow: 0 2px 8px rgba(0,0,0,0.2);\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "#chatbot .message, #chatbot .chatbot-message {\n",
        "  animation: fadeIn 0.25s ease-in-out;\n",
        "}\n",
        "\n",
        "@keyframes fadeIn {\n",
        "  from { opacity: 0; transform: translateY(6px); }\n",
        "  to { opacity: 1; transform: translateY(0); }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "/* Assistant/bot message bubble */\n",
        "#chatbot .message.bot,\n",
        "#chatbot .chatbot-message.bot {\n",
        "  background: #ffffff;\n",
        "  color: #2e3532;\n",
        "  border-radius: 12px 12px 12px 0; /* rounded bottom-right square */\n",
        "  padding: 10px 14px;\n",
        "  margin: 6px 0;\n",
        "  max-width: 80%;\n",
        "  box-shadow: 0 2px 8px rgba(0,0,0,0.15);\n",
        "}\n",
        "\n",
        "/* Textbox styling */\n",
        "#msg textarea {\n",
        "  background-color: #e0e2db !important;\n",
        "  color: #2e3532 !important;\n",
        "  border-radius: 8px !important;\n",
        "  padding: 8px !important;\n",
        "  box-shadow: none !important;\n",
        "}\n",
        "\n",
        "/* Button styling (Clear and default buttons) */\n",
        "#clear, .gr-button {\n",
        "  background-color: #01110A !important;\n",
        "  color: #e0e2db !important;\n",
        "  border: none !important;\n",
        "  box-shadow: none !important;\n",
        "}\n",
        "\n",
        "/* Title / markdown text color + CENTERING */\n",
        "#title {\n",
        "  color: #e0e2db;\n",
        "  text-align: center;\n",
        "  width: 100%;\n",
        "  display: block;\n",
        "  margin: 0 auto;\n",
        "}\n",
        "\n",
        "/* Ensure Gradio's dark borders don't show */\n",
        ".gradio-container .panel {\n",
        "  background: transparent !important;\n",
        "  box-shadow: none !important;\n",
        "}\n",
        "\n",
        "#footer {\n",
        "  text-align: center;\n",
        "  color: #01110A;\n",
        "  margin-top: 30px;\n",
        "  padding-top: 10px;\n",
        "  font-size: 14px;\n",
        "  opacity: 0.8;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(css=css, elem_id=\"root\") as demo:\n",
        "\n",
        "    gr.Markdown(\"## üìã Menu Chatbot\", elem_id=\"title\", elem_classes=[\"title\"])\n",
        "\n",
        "\n",
        "    chatbot = gr.Chatbot(value=[(\"Assistant\", \"Hello! How may I assist you today?\")], elem_id=\"chatbot\")\n",
        "\n",
        "    msg = gr.Textbox(\n",
        "        label=\"Your question\",\n",
        "        placeholder=\"Type and press Enter...\",\n",
        "        elem_id=\"msg\"\n",
        "    )\n",
        "\n",
        "    examples = gr.Examples(\n",
        "        examples=[\n",
        "            \"What are some good vegetarian options?\",\n",
        "            \"I am not so hungry, what is a good appetizer\",\n",
        "            \"If I want to order dessert what are my options?\"\n",
        "        ],\n",
        "        inputs=[msg]\n",
        "    )\n",
        "\n",
        "    clear = gr.Button(\"Clear\", elem_id=\"clear\")\n",
        "\n",
        "    msg.submit(chat_interface, [msg, chatbot], [chatbot, msg])\n",
        "    clear.click(lambda: [], None, chatbot)\n",
        "\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        <div id=\"footer\">\n",
        "            Built for the Resuarant ChatBot RAG Model Project ‚Äî Penn State ¬∑ 2025\n",
        "        </div>\n",
        "        \"\"\",\n",
        "        elem_id=\"footer\"\n",
        "    )\n",
        "\n",
        "\n",
        "with gr.Tabs():\n",
        "    with gr.Tab(\"Chat\"):\n",
        "        ...\n",
        "    with gr.Tab(\"About\"):\n",
        "        gr.Markdown(\"\"\"\n",
        "        ### ‚ÑπÔ∏è About This Project\n",
        "        This chatbot uses a Retrieval-Augmented Generation (RAG) pipeline\n",
        "        to answer questions about food waste based on EPA reports.\n",
        "        \"\"\")\n",
        "\n",
        "demo.launch(show_error=True)"
      ],
      "metadata": {
        "id": "RcbrB25vPejb"
      },
      "id": "RcbrB25vPejb",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
