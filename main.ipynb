{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b4ac5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\al4k9\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\~il'.\n",
      "  You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq \"unstructured[all-docs]\" pillow lxml\n",
    "%pip install -Uq chromadb tiktoken\n",
    "%pip install -Uq langchain langchain-community langchain-openai langchain-groq\n",
    "%pip install -Uq python_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af1c2193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1b7e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "output_path = \"C:/Users/al4k9/OneDrive/Desktop/RAG/RRMenu.pdf\"\n",
    "\n",
    "chunks = partition_pdf(\n",
    "    filename=output_path,                       # only required parameter\n",
    "    infer_table_structure=False,                # extract tables\n",
    "    strategy=\"auto\",                            # mandatory to infer tables, \"high-res\" if you extract tables\n",
    "    languages=[\"eng\"],\n",
    "    # extract_image_block_types=[\"Image\"],      # add 'Table' to list to extrac image of table\n",
    "    # extract_image_block_output_dir= \"path\",   # if none, images and tables will be saved in base64\n",
    "\n",
    "\n",
    "    # chunking groups related information | Useful for RAG\n",
    "    chunking_strategy=\"by_title\",               # or \"basic\" | Menu has clear titles\n",
    "    max_characters=10000,                       # max size of chunk\n",
    "    combine_text_under_n_chars=2000,            # comebine different elements when they are under 2000 characters\n",
    "    new_after_n_chars=6000                      # start new part after 6000 characters\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "413762b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d54e0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'CompositeElement',\n",
       " 'element_id': '43c2099fd4e91cc48e55834faccbbcbd',\n",
       " 'text': 'GOURMET FIRE-GRILLED BURGERS\\n\\nALL BURGERS INCLUDE A BOTTOMLESS SIDE\\n\\nSteak Fries • Yukon Chips • Steamed Broccoli • Side Salad Sweet Potato Fries (1.79) • Garlic Fries (1.79)\\n\\nOUR SIGNATURES Burgers you won’t find anywhere else. 100% Fresh, Never Frozen Beef.\\n\\nTHE SOUTHERN CHARM BURGER® Brown sugar glaze, candied bacon, Whiskey River® BBQ Sauce, Cheddar, caramelized onions, lettuce and mayo on a toasted brioche bun. 14.99 cal 1190\\n\\nBLACK & BLEU\\n\\nSautéed and blackened portobello mushrooms, caramelized onions, creamy cheese sauce, Bleu cheese crumbles, lettuce and roasted garlic aioli on a toasted brioche bun. 15.39 cal 980\\n\\nWHISKEY RIVER® BBQ\\n\\nDIP IT. DUNK IT. DOUSE YOUR BURGER.\\n\\nWhiskey River® BBQ Sauce, crispy onion straws, Cheddar, lettuce, tomatoes and mayo on a toasted sesame bun. 13.79 cal 1140 THE MADLOVE BURGER A Cheddar-and-Parmesan crisp, Provolone, Swiss, jalapeño relish, candied bacon, avocado, citrus- marinated tomatoes and red onions with lettuce on a toasted brioche bun. 15.39 cal 1060 BURNIN’ LOVE BURGER® Fried jalapeño coins, house-made salsa, Pepper-Jack, lettuce, tomatoes and chipotle aioli on a toasted sesame bun. 14.49 cal 920 Also available with grilled chicken. cal 740\\n\\nSMOKE & PEPPER™\\n\\nBlack-peppered bacon, Cheddar, lettuce, dill pickle planks and Smoke & Pepper™ ketchup on a toasted brioche bun. 14.99 cal 800\\n\\nSCORPION GOURMET BURGER\\n\\nSCORPION GOURMET BURGER Scorpion Pepper Sauce, Pepper-Jack, fried jalapeño coins, lettuce, tomatoes, pickles, red onions and jalapeños roasted in Scorpion sauce and roasted garlic aioli on a toasted sesame bun. 15.39 cal 960\\n\\nROYAL RED ROBIN BURGER® Hardwood-smoked bacon, egg♦, American cheese, lettuce, tomatoes and mayo on a toasted sesame bun. 14.49 cal 1100\\n\\nBANZAI\\n\\nTeriyaki-glazed patty, grilled pineapple, Cheddar, lettuce, tomatoes and mayo on a toasted sesame bun. 13.69 cal 950\\n\\nLimited Time PRETZEL BACON BEER-CHEESE BURGER\\n\\nFire-grilled beef burger topped with Cheddar cheese, hardwood-smoked bacon and mayo on a toasted pretzel bun. Served with New Belgium® Fat Tire® beer cheese fondue for dipping and Bottomless Steak Fries®. 15.29 cal 1730 Dip It. Dunk It. Douse It.',\n",
       " 'metadata': {'file_directory': 'C:/Users/al4k9/OneDrive/Desktop/RAG',\n",
       "  'filename': 'RRMenu.pdf',\n",
       "  'languages': ['eng'],\n",
       "  'last_modified': '2025-11-24T20:05:21',\n",
       "  'page_number': 1,\n",
       "  'orig_elements': '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',\n",
       "  'filetype': 'application/pdf'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4fb0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<unstructured.documents.elements.CompositeElement object at 0x000001709538E450>, <unstructured.documents.elements.CompositeElement object at 0x00000170953C0B90>, <unstructured.documents.elements.CompositeElement object at 0x00000170953C0050>, <unstructured.documents.elements.CompositeElement object at 0x000001709C003BD0>, <unstructured.documents.elements.CompositeElement object at 0x000001709C0003D0>, <unstructured.documents.elements.CompositeElement object at 0x000001709C6564E0>, <unstructured.documents.elements.CompositeElement object at 0x000001708D3AE990>, <unstructured.documents.elements.CompositeElement object at 0x000001709527B4D0>, <unstructured.documents.elements.CompositeElement object at 0x0000017095358F70>]\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "\n",
    "for chunk in chunks:\n",
    "    if \"CompositeElement\" in str(type((chunk))):\n",
    "        texts.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09174086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6c9ad59",
   "metadata": {},
   "outputs": [
    {
     "ename": "GroqError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mGroqError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      1\u001b[39m prompt_text = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33mYou are an assistant tasked with summarizing text.\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33mGive a concise summary of the text.\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m \n\u001b[32m     11\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     13\u001b[39m prompt = ChatPromptTemplate.from_template(prompt_text)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m model = \u001b[43mChatGroq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mllama-3.1-8b-instant\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m summarize_chain = prompt | model | StrOutputParser()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\langchain_core\\load\\serializable.py:116\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    115\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\langchain_groq\\chat_models.py:489\u001b[39m, in \u001b[36mChatGroq.validate_environment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    487\u001b[39m sync_specific: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = {\u001b[33m\"\u001b[39m\u001b[33mhttp_client\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.http_client}\n\u001b[32m    488\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.client:\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[38;5;28mself\u001b[39m.client = \u001b[43mgroq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGroq\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msync_specific\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.chat.completions\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.async_client:\n\u001b[32m    493\u001b[39m     async_specific: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = {\u001b[33m\"\u001b[39m\u001b[33mhttp_client\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.http_async_client}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\groq\\_client.py:79\u001b[39m, in \u001b[36mGroq.__init__\u001b[39m\u001b[34m(self, api_key, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m     77\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mGROQ_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m GroqError(\n\u001b[32m     80\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     81\u001b[39m     )\n\u001b[32m     82\u001b[39m \u001b[38;5;28mself\u001b[39m.api_key = api_key\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m base_url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mGroqError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the GROQ_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "prompt_text = \"\"\"\n",
    "You are an assistant tasked with summarizing text.\n",
    "Give a concise summary of the text.\n",
    "\n",
    "Respond only with the summary, no additional comments.\n",
    "Do not start your message by saying \"Here is a summary\" or anything like that.\n",
    "Just give me the summary as it is.\n",
    "\n",
    "Text chunk: {element}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "model = ChatGroq(temperature=0.5, model=\"llama-3.1-8b-instant\")\n",
    "summarize_chain = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e26e188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|          | 0/2 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\_core\\memmap.py:272\u001b[39m, in \u001b[36mmemmap.__new__\u001b[39m\u001b[34m(subtype, filename, dtype, mode, offset, shape, order)\u001b[39m\n\u001b[32m    271\u001b[39m         fid.write(\u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\0\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m         \u001b[43mfid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mc\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[31mOSError\u001b[39m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m offload_folder = os.path.join(os.getcwd(), \u001b[33m\"\u001b[39m\u001b[33moffload\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m os.makedirs(offload_folder, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Your custom prompt template\u001b[39;00m\n\u001b[32m     19\u001b[39m prompt_template = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[33mYou are an assistant tasked with summarizing text.\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[33mGive a concise summary of the text.\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m \u001b[33mText chunk: \u001b[39m\u001b[38;5;132;01m{element}\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\models\\auto\\auto_factory.py:604\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    603\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    608\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    610\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\modeling_utils.py:277\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    279\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\modeling_utils.py:5048\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   5038\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5039\u001b[39m         torch.set_default_dtype(dtype_orig)\n\u001b[32m   5041\u001b[39m     (\n\u001b[32m   5042\u001b[39m         model,\n\u001b[32m   5043\u001b[39m         missing_keys,\n\u001b[32m   5044\u001b[39m         unexpected_keys,\n\u001b[32m   5045\u001b[39m         mismatched_keys,\n\u001b[32m   5046\u001b[39m         offload_index,\n\u001b[32m   5047\u001b[39m         error_msgs,\n\u001b[32m-> \u001b[39m\u001b[32m5048\u001b[39m     ) = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5049\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5050\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5051\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5052\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5053\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5054\u001b[39m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5055\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5056\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5057\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5058\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5059\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5060\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5061\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5062\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5063\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5064\u001b[39m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[32m   5065\u001b[39m model.tie_weights()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\modeling_utils.py:5468\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[39m\n\u001b[32m   5465\u001b[39m         args_list = logging.tqdm(args_list, desc=\u001b[33m\"\u001b[39m\u001b[33mLoading checkpoint shards\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   5467\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m args_list:\n\u001b[32m-> \u001b[39m\u001b[32m5468\u001b[39m         _error_msgs, disk_offload_index = \u001b[43mload_shard_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5469\u001b[39m         error_msgs += _error_msgs\n\u001b[32m   5471\u001b[39m \u001b[38;5;66;03m# Save offloaded index if needed\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\modeling_utils.py:843\u001b[39m, in \u001b[36mload_shard_file\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m    841\u001b[39m \u001b[38;5;66;03m# Skip it with fsdp on ranks other than 0\u001b[39;00m\n\u001b[32m    842\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized):\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m     disk_offload_index = \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreverse_key_renaming_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m error_msgs, disk_offload_index\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\modeling_utils.py:765\u001b[39m, in \u001b[36m_load_state_dict_into_meta_model\u001b[39m\u001b[34m(model, state_dict, shard_file, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, hf_quantizer, keep_in_fp32_regex, device_mesh)\u001b[39m\n\u001b[32m    763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m param_device == \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    764\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_safetensors:\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m         disk_offload_index = \u001b[43moffload_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    766\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m hf_quantizer.param_needs_quantization(model, param_name):\n\u001b[32m    767\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_fsdp_enabled():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\accelerate\\utils\\offload.py:40\u001b[39m, in \u001b[36moffload_weight\u001b[39m\u001b[34m(weight, weight_name, offload_folder, index)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m array.ndim == \u001b[32m0\u001b[39m:\n\u001b[32m     39\u001b[39m     array = array[\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m file_array = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmemmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43marray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mw+\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43marray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m file_array[:] = array[:]\n\u001b[32m     42\u001b[39m file_array.flush()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\_core\\memmap.py:239\u001b[39m, in \u001b[36mmemmap.__new__\u001b[39m\u001b[34m(subtype, filename, dtype, mode, offset, shape, order)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    234\u001b[39m     f_ctx = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    235\u001b[39m         os.fspath(filename),\n\u001b[32m    236\u001b[39m         (\u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mc\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m mode)+\u001b[33m'\u001b[39m\u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    237\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m f_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[32m    240\u001b[39m     fid.seek(\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    241\u001b[39m     flen = fid.tell()\n",
      "\u001b[31mOSError\u001b[39m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Load the model\n",
    "model_name = \"mosaicml/mpt-7b-instruct\"  # free instruct model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# Create an offload folder\n",
    "offload_folder = os.path.join(os.getcwd(), \"offload\")\n",
    "os.makedirs(offload_folder, exist_ok=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    offload_folder=offload_folder\n",
    ")\n",
    "\n",
    "# Your custom prompt template\n",
    "prompt_template = \"\"\"\n",
    "You are an assistant tasked with summarizing text.\n",
    "Give a concise summary of the text.\n",
    "\n",
    "Respond only with the summary, no additional comments.\n",
    "Do not start your message by saying \"Here is a summary\" or anything like that.\n",
    "Just give me the summary as it is.\n",
    "\n",
    "Text chunk: {element}\n",
    "\"\"\"\n",
    "\n",
    "def summarize_text(element, max_new_tokens=200):\n",
    "    \"\"\"\n",
    "    Summarize a single text chunk using a local LLM with the custom prompt.\n",
    "    \n",
    "    Args:\n",
    "        element (str): Text chunk to summarize.\n",
    "        max_new_tokens (int): Max tokens for the summary.\n",
    "    \n",
    "    Returns:\n",
    "        str: The concise summary.\n",
    "    \"\"\"\n",
    "    prompt = prompt_template.format(element=element)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary.strip()\n",
    "\n",
    "summary = []\n",
    "for chunk in texts:\n",
    "    summary.append(summarize_text(chunk))\n",
    "print(summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
