{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97b4ac5f",
      "metadata": {
        "id": "97b4ac5f",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install -U pip\n",
        "%pip install -Uq \"unstructured[all-docs]\" Pillow lxml\n",
        "%pip install -Uq chromadb tiktoken\n",
        "%pip install -Uq langchain langchain-community langchain-openai\n",
        "%pip install -Uq python_dotenv\n",
        "!apt-get update\n",
        "!apt-get install -y poppler-utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Need for Colab\n",
        "!pip install -q --upgrade \"Pillow<11\""
      ],
      "metadata": {
        "id": "tKRg1bsUiVFh"
      },
      "id": "tKRg1bsUiVFh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af1c2193",
      "metadata": {
        "id": "af1c2193"
      },
      "outputs": [],
      "source": [
        "#For Local Run\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XmtivmNcutCx",
      "metadata": {
        "id": "XmtivmNcutCx"
      },
      "outputs": [],
      "source": [
        "#For Colab Run\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b1b7e32",
      "metadata": {
        "id": "1b1b7e32"
      },
      "outputs": [],
      "source": [
        "from unstructured.partition.pdf import partition_pdf\n",
        "import os\n",
        "\n",
        "path = os.path.join(os.getcwd(), \"drive/MyDrive/Colab Notebooks/RAG/RRMenu.pdf\")\n",
        "\n",
        "chunks = partition_pdf(\n",
        "    filename=path,                                                              # only required parameter\n",
        "    infer_table_structure=False,                                                 # extract tables\n",
        "    strategy=\"auto\",                                                            # mandatory to infer tables, \"high-res\" if you extract tables\n",
        "    languages=[\"eng\"],\n",
        "    skip_infer_table_types=True,\n",
        "    # extract_image_block_types=[\"Image\"],                                      # add 'Table' to list to extrac image of table\n",
        "    # extract_image_block_output_dir= \"path\",                                   # if none, images and tables will be saved in base64\n",
        "\n",
        "    # chunking groups related information | Useful for RAG\n",
        "    chunking_strategy=\"by_title\",                                               # or \"basic\" | Menu has clear titles\n",
        "    max_characters=10000,                                                       # max size of chunk\n",
        "    combine_text_under_n_chars=2000,                                            # comebine different elements when they are under 2000 characters\n",
        "    new_after_n_chars=6000                                                      # start new part after 6000 characters\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "413762b4",
      "metadata": {
        "id": "413762b4"
      },
      "outputs": [],
      "source": [
        "print(len(chunks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d54e0e3",
      "metadata": {
        "id": "0d54e0e3"
      },
      "outputs": [],
      "source": [
        "chunks[0].to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be4fb0df",
      "metadata": {
        "id": "be4fb0df"
      },
      "outputs": [],
      "source": [
        "texts = []\n",
        "\n",
        "#Incase we decide to extract images/tables in the future\n",
        "for chunk in chunks:\n",
        "    if \"CompositeElement\" in str(type((chunk))):\n",
        "        texts.append(chunk)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "\n",
        "# Chunks --> Langchain Documents\n",
        "documents = []\n",
        "for chunk in texts:\n",
        "  documents.append(Document(page_content = chunk.text,\n",
        "                            metadata=chunk.metadata.to_dict()                   # Document() expects metadata as a dict, not unstrucuted metadata\n",
        "                            )\n",
        "  )\n",
        "\n",
        "# print(documents[0])"
      ],
      "metadata": {
        "id": "1mZY8qB6Ao-T"
      },
      "id": "1mZY8qB6Ao-T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
        "from langchain_community.vectorstores import Chroma\n",
        "import shutil, os\n",
        "\n",
        "filtered_docs = filter_complex_metadata(documents)                              # langchain doesnt like unstructureds metadata structure\n",
        "\n",
        "# create embeddings for vector storage\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")               # huggingface is free\n",
        "\n",
        "# remove chroma_db so you dont re-store data\n",
        "shutil.rmtree(\"./chroma_db\", ignore_errors=True)\n",
        "os.makedirs(\"./chroma_db\", exist_ok=True)\n",
        "\n",
        "# Create vectorstore\n",
        "vectorstore = Chroma.from_documents(filtered_docs,\n",
        "                                    embeddings,\n",
        "                                    persist_directory=\"./chroma_db\"\n",
        "                                    )"
      ],
      "metadata": {
        "id": "to4GxaNFDNYF"
      },
      "id": "to4GxaNFDNYF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get a tuple of the top k chunks and their scores based on their similarity score (i.e. cosine sim)\n",
        "results = vectorstore.similarity_search_with_relevance_scores(\"Can i make a custom pizza?\", k=3)\n",
        "\n",
        "# print top k docs and their score\n",
        "for doc, score in results:\n",
        "    print(f\"Score:  {score} \\nText: {doc.page_content} \\n {'-'*100}\")"
      ],
      "metadata": {
        "id": "VCsT_mTtJA9g"
      },
      "id": "VCsT_mTtJA9g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers, torch, os\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(token=os.getenv(\"HF_TOKEN\"))\n",
        "\n",
        "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "\n",
        "pipe = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    model_kwargs={\"torch_dtype\": torch.bfloat16},                               # half the size of weight\n",
        "    device_map=\"auto\"                                                           # tries gpu, then cpu\n",
        ")\n"
      ],
      "metadata": {
        "id": "iExRWcD8eoX0"
      },
      "id": "iExRWcD8eoX0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Which burgers are vegetarian?\"                                         # user input\n",
        "context = \"\\n\\n\".join(doc.page_content for doc, _ in results[:3])\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"Answer only from the menu below. Be brief.\"},\n",
        "    {\"role\": \"user\", \"content\": f\"Menu:\\n{context}\\n\\n{query}\"}\n",
        "]\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=150,                                                         # number of tokens to generate\n",
        "    temperature=0.6,                                                            # more likely to select most probable word (logit / 0.7)\n",
        "    do_sample=True,                                                             # need to set this to true for temperature to have any effect\n",
        "    top_p=0.9,                                                                  # model choses from top tokens that make up 90% of the probability mass (ignores super low prob tokens from being selected)\n",
        "    pad_token_id=pipe.tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "# last element is the llm reply\n",
        "answer = outputs[0][\"generated_text\"][-1][\"content\"]\n",
        "# print(answer)"
      ],
      "metadata": {
        "id": "ETfK9XRDStHO"
      },
      "id": "ETfK9XRDStHO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def chat_interface(message, history):\n",
        "    response = answer(message)\n",
        "    history.append((message, response))\n",
        "    return history, \"\"   # clear textbox\n",
        "\n",
        "css = \"\"\"\n",
        "\n",
        "@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&display=swap');\n",
        "\n",
        "* {\n",
        "  font-family: \"Inter\", sans-serif !important;\n",
        "}\n",
        "\n",
        "/* Root background and general text color */\n",
        "#root {\n",
        "  background-color: #2e3532;\n",
        "  color: #e0e2db;\n",
        "  padding: 18px;\n",
        "  min-height: 100vh;\n",
        "}\n",
        "\n",
        "/* Chat container (box that holds messages) */\n",
        "#chatbot {\n",
        "  background-color: #e0e2db;\n",
        "  color: #2e3532;\n",
        "  border-radius: 12px;\n",
        "  padding: 20px;\n",
        "  max-height: 480px;\n",
        "  overflow-y: auto;\n",
        "  margin: 0 auto;\n",
        "  width: 85%;\n",
        "  box-shadow: 0px 4px 18px rgba(0,0,0,0.15);\n",
        "}\n",
        "\n",
        "/* User message bubble (attempt to match Gradio's generated classes) */\n",
        "#chatbot .message.user,\n",
        "#chatbot .chatbot-message.user {\n",
        "  background: #73BA9B;\n",
        "  color: white;\n",
        "  border-radius: 12px 12px 0 12px; /* rounded bottom-left square */\n",
        "  padding: 10px 14px;\n",
        "  margin: 6px 0;\n",
        "  max-width: 80%;\n",
        "  box-shadow: 0 2px 8px rgba(0,0,0,0.2);\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "#chatbot .message, #chatbot .chatbot-message {\n",
        "  animation: fadeIn 0.25s ease-in-out;\n",
        "}\n",
        "\n",
        "@keyframes fadeIn {\n",
        "  from { opacity: 0; transform: translateY(6px); }\n",
        "  to { opacity: 1; transform: translateY(0); }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "/* Assistant/bot message bubble */\n",
        "#chatbot .message.bot,\n",
        "#chatbot .chatbot-message.bot {\n",
        "  background: #ffffff;\n",
        "  color: #2e3532;\n",
        "  border-radius: 12px 12px 12px 0; /* rounded bottom-right square */\n",
        "  padding: 10px 14px;\n",
        "  margin: 6px 0;\n",
        "  max-width: 80%;\n",
        "  box-shadow: 0 2px 8px rgba(0,0,0,0.15);\n",
        "}\n",
        "\n",
        "/* Textbox styling */\n",
        "#msg textarea {\n",
        "  background-color: #e0e2db !important;\n",
        "  color: #2e3532 !important;\n",
        "  border-radius: 8px !important;\n",
        "  padding: 8px !important;\n",
        "  box-shadow: none !important;\n",
        "}\n",
        "\n",
        "/* Button styling (Clear and default buttons) */\n",
        "#clear, .gr-button {\n",
        "  background-color: #01110A !important;\n",
        "  color: #e0e2db !important;\n",
        "  border: none !important;\n",
        "  box-shadow: none !important;\n",
        "}\n",
        "\n",
        "/* Title / markdown text color + CENTERING */\n",
        "#title {\n",
        "  color: #e0e2db;\n",
        "  text-align: center;\n",
        "  width: 100%;\n",
        "  display: block;\n",
        "  margin: 0 auto;\n",
        "}\n",
        "\n",
        "/* Ensure Gradio's dark borders don't show */\n",
        ".gradio-container .panel {\n",
        "  background: transparent !important;\n",
        "  box-shadow: none !important;\n",
        "}\n",
        "\n",
        "#footer {\n",
        "  text-align: center;\n",
        "  color: #01110A;\n",
        "  margin-top: 30px;\n",
        "  padding-top: 10px;\n",
        "  font-size: 14px;\n",
        "  opacity: 0.8;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(css=css, elem_id=\"root\") as demo:\n",
        "\n",
        "    gr.Markdown(\"## Menu Chatbot\", elem_id=\"title\", elem_classes=[\"title\"])\n",
        "\n",
        "\n",
        "    chatbot = gr.Chatbot(value=[(\"Assistant\", \"Hello! How may I assist you today?\")], elem_id=\"chatbot\")\n",
        "\n",
        "    msg = gr.Textbox(\n",
        "        label=\"Your question\",\n",
        "        placeholder=\"Type and press Enter...\",\n",
        "        elem_id=\"msg\"\n",
        "    )\n",
        "\n",
        "    examples = gr.Examples(\n",
        "        examples=[\n",
        "            \"What are some good vegetarian options?\",\n",
        "            \"I am not so hungry, what is a good appetizer\",\n",
        "            \"If I want to order dessert what are my options?\"\n",
        "        ],\n",
        "        inputs=[msg]\n",
        "    )\n",
        "\n",
        "    clear = gr.Button(\"Clear\", elem_id=\"clear\")\n",
        "\n",
        "    msg.submit(chat_interface, [msg, chatbot], [chatbot, msg])\n",
        "    clear.click(lambda: [], None, chatbot)\n",
        "\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        <div id=\"footer\">\n",
        "            Built for the Resuarant ChatBot RAG Model Project — Penn State · 2025\n",
        "        </div>\n",
        "        \"\"\",\n",
        "        elem_id=\"footer\"\n",
        "    )\n",
        "\n",
        "\n",
        "with gr.Tabs():\n",
        "    with gr.Tab(\"Chat\"):\n",
        "        ...\n",
        "    with gr.Tab(\"About\"):\n",
        "        gr.Markdown(\"\"\"\n",
        "        ### ℹ About This Project\n",
        "        This chatbot uses a Retrieval-Augmented Generation (RAG) pipeline\n",
        "        to answer questions about food waste based on EPA reports.\n",
        "        \"\"\")\n",
        "\n",
        "demo.launch(show_error=True)"
      ],
      "metadata": {
        "id": "RcbrB25vPejb"
      },
      "id": "RcbrB25vPejb",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}